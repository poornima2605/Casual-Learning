{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from causal_meta.modules.categorical import Marginal, Conditional\n",
    "from causal_meta.bivariate.structural1 import BivariateStructuralModel\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, N):\n",
    "        super(Model, self).__init__()\n",
    "        self.N = N\n",
    "\n",
    "    def set_maximum_likelihood(self, inputs):\n",
    "        inputs_A, inputs_B , inputs_C = np.split(inputs.numpy(), 3, axis=1)\n",
    "        num_samples = inputs_A.shape[0]\n",
    "        \n",
    "        pi_A = np.zeros((self.N,), dtype=np.float64)\n",
    "        pi_B_A = np.zeros((self.N, self.N), dtype=np.float64)\n",
    "        pi_C_B = np.zeros((self.N, self.N), dtype=np.float64)\n",
    "        \n",
    "        # Empirical counts for p(A)\n",
    "        for i in range(num_samples):\n",
    "            pi_A[inputs_A[i, 0]] += 1\n",
    "        pi_A /= float(num_samples)\n",
    "        assert np.isclose(np.sum(pi_A, axis=0), 1.)\n",
    "        \n",
    "        # Empirical counts for p(B | A)\n",
    "        for i in range(num_samples):\n",
    "            pi_B_A[inputs_A[i, 0], inputs_B[i, 0]] += 1\n",
    "        pi_B_A /= np.maximum(np.sum(pi_B_A, axis=1, keepdims=True), 1.)\n",
    "        sum_pi_B_A = np.sum(pi_B_A, axis=1)\n",
    "        assert np.allclose(sum_pi_B_A[sum_pi_B_A > 0], 1.)\n",
    "        \n",
    "        # Empirical counts for p(C | B)\n",
    "        for i in range(num_samples):\n",
    "            pi_C_B[inputs_B[i, 0], inputs_C[i, 0]] += 1\n",
    "        pi_C_B /= np.maximum(np.sum(pi_C_B, axis=1, keepdims=True), 1.)\n",
    "        sum_pi_C_B = np.sum(pi_C_B, axis=1)\n",
    "        assert np.allclose(sum_pi_C_B[sum_pi_C_B > 0], 1.)\n",
    "\n",
    "\n",
    "        return self.set_analytical_maximum_likelihood(pi_A, pi_B_A, pi_C_B)\n",
    "    \n",
    "class Model_new(nn.Module):\n",
    "    def __init__(self, N):\n",
    "        super(Model_new, self).__init__()\n",
    "        self.N = N\n",
    "\n",
    "    def set_maximum_likelihood(self, inputs):\n",
    "        inputs_A, inputs_B , inputs_C = np.split(inputs.numpy(), 3, axis=1)\n",
    "        num_samples = inputs_A.shape[0]\n",
    "        \n",
    "        pi_B = np.zeros((self.N,), dtype=np.float64)\n",
    "        pi_B_A = np.zeros((self.N, self.N), dtype=np.float64)\n",
    "        pi_B_C = np.zeros((self.N, self.N), dtype=np.float64)\n",
    "        \n",
    "        # Empirical counts for p(B)\n",
    "        for i in range(num_samples):\n",
    "            pi_B[inputs_B[i, 0]] += 1\n",
    "        pi_B /= float(num_samples)\n",
    "        assert np.isclose(np.sum(pi_B, axis=0), 1.)\n",
    "        \n",
    "        # Empirical counts for p(B | C)\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            pi_B_C[inputs_C[i, 0] , inputs_B[i, 0]] += 1\n",
    "        pi_B_C /= np.maximum(np.sum(pi_B_C, axis=1, keepdims=True), 1.)\n",
    "        sum_pi_B_C = np.sum(pi_B_C, axis=1)\n",
    "        assert np.allclose(sum_pi_B_A_C[sum_pi_B_C > 0], 1.)\n",
    "        \n",
    "        # Empirical counts for p(B | A)\n",
    "        for i in range(num_samples):\n",
    "            pi_B_A[inputs_A[i, 0], inputs_B[i, 0]] += 1\n",
    "        pi_B_A /= np.maximum(np.sum(pi_B_A, axis=1, keepdims=True), 1.)\n",
    "        sum_pi_B_A = np.sum(pi_B_A, axis=1)\n",
    "        assert np.allclose(sum_pi_B_A[sum_pi_B_A > 0], 1.)\n",
    "        \n",
    "\n",
    "        return self.set_analytical_maximum_likelihood(pi_B, pi_B_A, pi_B_C)\n",
    "\n",
    "class Model1(Model):\n",
    "    def __init__(self, N):\n",
    "        super(Model1, self).__init__(N=N)\n",
    "        self.p_A = Marginal(N)\n",
    "        self.p_B_A = Conditional(N)\n",
    "        self.p_C_B = Conditional(N)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Compute the (negative) log-likelihood with the\n",
    "        # decomposition p(x_A, x_B ,x_C) = p(x_A) p(x_B | x_A) p(x_C | x_B)\n",
    "        #print(inputs)\n",
    "        inputs_A, inputs_B, inputs_C = torch.split(inputs, 1, dim=1)\n",
    "        #print(inputs_C)\n",
    "        inputs_A, inputs_B, inputs_C = inputs_A.squeeze(1), inputs_B.squeeze(1), inputs_C.squeeze(1)\n",
    "\n",
    "        return self.p_A(inputs_A) + self.p_B_A(inputs_A, inputs_B) + self.p_C_B(inputs_B, inputs_C)\n",
    "\n",
    "    def set_analytical_maximum_likelihood(self, pi_A, pi_B_A, pi_C_B):\n",
    "        pi_A_th = torch.from_numpy(pi_A)\n",
    "        pi_B_A_th = torch.from_numpy(pi_B_A)\n",
    "        pi_C_B_th = torch.from_numpy(pi_C_B)\n",
    "        \n",
    "        self.p_A.w.data = torch.log(pi_A_th)\n",
    "        self.p_B_A.w.data = torch.log(pi_B_A_th)\n",
    "        self.p_C_B.w.data = torch.log(pi_C_B_th)\n",
    "\n",
    "    def init_parameters(self):\n",
    "        self.p_A.init_parameters()\n",
    "        self.p_B_A.init_parameters()\n",
    "        self.p_C_B.init_parameters()\n",
    "        \n",
    "class Model2(Model):\n",
    "    def __init__(self, N):\n",
    "        super(Model2, self).__init__(N=N)\n",
    "        self.p_C = Marginal(N)\n",
    "        self.p_B_C = Conditional(N)\n",
    "        self.p_A_B = Conditional(N)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Compute the (negative) log-likelihood with the\n",
    "        # decomposition p(x_A, x_B, x_C) = p(x_C)p(x_B | x_C)p(x_A|x_B)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = torch.split(inputs, 1, dim=1)\n",
    "        inputs_A, inputs_B, inputs_C = inputs_A.squeeze(1), inputs_B.squeeze(1), inputs_C.squeeze(1)\n",
    "        \n",
    "        return self.p_C(inputs_C) + self.p_B_C(inputs_C, inputs_B) + self.p_A_B(inputs_B, inputs_A) \n",
    "\n",
    "    def set_analytical_maximum_likelihood(self, pi_A, pi_B_A, pi_C_B):\n",
    "        pi_A_th = torch.from_numpy(pi_A)\n",
    "        pi_B_A_th = torch.from_numpy(pi_B_A)\n",
    "        pi_C_B_th = torch.from_numpy(pi_C_B)\n",
    "        \n",
    "        log_joint1 = torch.log(pi_A_th.unsqueeze(1)) + torch.log(pi_B_A_th)\n",
    "        log_p_B = torch.logsumexp(log_joint1, dim=0)\n",
    "        \n",
    "        log_joint2 = torch.log(log_p_B.unsqueeze(1)) + torch.log(pi_C_B_th)\n",
    "        log_p_C = torch.logsumexp(log_joint2, dim=0)\n",
    "        \n",
    "        self.p_C.w.data = log_p_C\n",
    "        self.p_B_C.w.data = log_joint2.t() - log_p_C.unsqueeze(1)\n",
    "        self.p_A_B.w.data = log_joint1.t() - log_p_B.unsqueeze(1)\n",
    "\n",
    "    def init_parameters(self):\n",
    "        self.p_C.init_parameters()\n",
    "        self.p_B_C.init_parameters()\n",
    "        self.p_A_B.init_parameters()\n",
    "        \n",
    "class Model3(Model):\n",
    "    def __init__(self, N):\n",
    "        super(Model3, self).__init__(N=N)\n",
    "        self.p_B = Marginal(N)\n",
    "        self.p_A_B = Conditional(N)\n",
    "        self.p_C_A = Conditional(N)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Compute the (negative) log-likelihood with the\n",
    "        # decomposition p(x_A, x_B, x_C) = p(x_B)p(x_A | x_B)p(x_C|x_A)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = torch.split(inputs, 1, dim=1)\n",
    "        inputs_A, inputs_B, inputs_C = inputs_A.squeeze(1), inputs_B.squeeze(1), inputs_C.squeeze(1)\n",
    "        \n",
    "        return self.p_B(inputs_B) + self.p_A_B(inputs_B, inputs_A) + self.p_C_A(inputs_A, inputs_C) \n",
    "\n",
    "    def set_analytical_maximum_likelihood(self, pi_A, pi_B_A, pi_C_B):\n",
    "        pi_A_th = torch.from_numpy(pi_A)\n",
    "        pi_B_A_th = torch.from_numpy(pi_B_A)\n",
    "        pi_C_B_th = torch.from_numpy(pi_C_B)\n",
    "        \n",
    "        log_joint1 = torch.log(pi_A_th.unsqueeze(1)) + torch.log(pi_B_A_th)\n",
    "        log_p_B = torch.logsumexp(log_joint1, dim=0)\n",
    "        \n",
    "        log_joint2 = torch.log(log_p_B.unsqueeze(1)) + torch.log(pi_C_B_th) \n",
    "        log_p_C = torch.logsumexp(log_joint2, dim=0)\n",
    "        \n",
    "        log_joint3 = log_p_C + torch.log(pi_C_B_th) + torch.log(pi_B_A_th)\n",
    "        \n",
    "        self.p_B.w.data = log_p_B\n",
    "        self.p_A_B.w.data = log_joint1.t() - log_p_B.unsqueeze(1)\n",
    "        self.p_C_A.w.data = log_joint3.t() - torch.log(pi_A_th.unsqueeze(1))\n",
    "\n",
    "    def init_parameters(self):\n",
    "        self.p_B.init_parameters()\n",
    "        self.p_A_B.init_parameters()\n",
    "        self.p_C_A.init_parameters()\n",
    "        \n",
    "class Model4(Model):\n",
    "    def __init__(self, N):\n",
    "        super(Model4, self).__init__(N=N)\n",
    "        self.p_C = Marginal(N)\n",
    "        self.p_A_C = Conditional(N)\n",
    "        self.p_B_A = Conditional(N)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Compute the (negative) log-likelihood with the\n",
    "        # decomposition p(x_A, x_B, x_C) = p(x_C)p(x_A | x_C)p(x_B|x_A)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = torch.split(inputs, 1, dim=1)\n",
    "        inputs_A, inputs_B, inputs_C = inputs_A.squeeze(1), inputs_B.squeeze(1), inputs_C.squeeze(1)\n",
    "        \n",
    "        return self.p_C(inputs_C) + self.p_A_C(inputs_C, inputs_A) + self.p_B_A(inputs_A, inputs_B) \n",
    "\n",
    "    def set_analytical_maximum_likelihood(self, pi_A, pi_B_A, pi_C_B):\n",
    "        pi_A_th = torch.from_numpy(pi_A)\n",
    "        pi_B_A_th = torch.from_numpy(pi_B_A)\n",
    "        pi_C_B_th = torch.from_numpy(pi_C_B)\n",
    "        \n",
    "        log_joint1 = torch.log(pi_A_th.unsqueeze(1)) + torch.log(pi_B_A_th)\n",
    "        log_p_B = torch.logsumexp(log_joint1, dim=0)\n",
    "        \n",
    "        log_joint2 = torch.log(log_p_B.unsqueeze(1)) + torch.log(pi_C_B_th) \n",
    "        log_p_C = torch.logsumexp(log_joint2, dim=0)\n",
    "        \n",
    "        log_p_C_A = (log_p_C + torch.log(pi_C_B_th) + torch.log(pi_B_A_th)).t - torch.log(pi_A_th.unsqueeze(1))\n",
    "        log_joint3 = torch.log(pi_A_th.unsqueeze(1)) + log_p_C_A\n",
    "        \n",
    "        self.p_C.w.data = log_p_C\n",
    "        self.p_A_C.w.data = log_joint3.t() - log_p_C.unsqueeze(1)\n",
    "        self.p_B_A.w.data = torch.log(pi_B_A_th)\n",
    "\n",
    "    def init_parameters(self):\n",
    "        self.p_C.init_parameters()\n",
    "        self.p_A_C.init_parameters()\n",
    "        self.p_B_A.init_parameters()\n",
    "        \n",
    "class Model5(Model):\n",
    "    def __init__(self, N):\n",
    "        super(Model5, self).__init__(N=N)\n",
    "        self.p_A = Marginal(N)\n",
    "        self.p_C_A = Conditional(N)\n",
    "        self.p_B_C = Conditional(N)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Compute the (negative) log-likelihood with the\n",
    "        # decomposition p(x_A, x_B, x_C) = p(x_C)p(x_A | x_C)p(x_B|x_A)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = torch.split(inputs, 1, dim=1)\n",
    "        inputs_A, inputs_B, inputs_C = inputs_A.squeeze(1), inputs_B.squeeze(1), inputs_C.squeeze(1)\n",
    "        \n",
    "        return self.p_A(inputs_A) + self.p_C_A(inputs_A, inputs_C) + self.p_B_A(inputs_A, inputs_B) \n",
    "\n",
    "    def set_analytical_maximum_likelihood(self, pi_A, pi_B_A, pi_C_B):\n",
    "        pi_A_th = torch.from_numpy(pi_A)\n",
    "        pi_B_A_th = torch.from_numpy(pi_B_A)\n",
    "        pi_C_B_th = torch.from_numpy(pi_C_B)\n",
    "        \n",
    "        log_joint1 = torch.log(pi_A_th.unsqueeze(1)) + torch.log(pi_B_A_th)\n",
    "        log_p_B = torch.logsumexp(log_joint1, dim=0)\n",
    "        \n",
    "        log_joint2 = torch.log(log_p_B.unsqueeze(1)) + torch.log(pi_C_B_th) \n",
    "        log_p_C = torch.logsumexp(log_joint2, dim=0)\n",
    "        \n",
    "        log_joint3 = log_p_C + torch.log(pi_C_B_th) + torch.log(pi_B_A_th) \n",
    "        \n",
    "        self.p_A.w.data = torch.log(pi_A_th)\n",
    "        self.p_C_A.w.data = log_joint3.t() - torch.log(pi_A_th.unsqueeze(1))\n",
    "        self.p_B_C.w.data = log_joint2.t() - log_p_C.unsqueeze(1)\n",
    "\n",
    "    def init_parameters(self):\n",
    "        self.p_A.init_parameters()\n",
    "        self.p_C_A.init_parameters()\n",
    "        self.p_B_C.init_parameters()\n",
    "        \n",
    "class Model6(Model):\n",
    "    def __init__(self, N):\n",
    "        super(Model6, self).__init__(N=N)\n",
    "        self.p_B = Marginal(N)\n",
    "        self.p_C_B = Conditional(N)\n",
    "        self.p_A_C = Conditional(N)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Compute the (negative) log-likelihood with the\n",
    "        # decomposition p(x_A, x_B, x_C) = p(x_C)p(x_A | x_C)p(x_B|x_A)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = torch.split(inputs, 1, dim=1)\n",
    "        inputs_A, inputs_B, inputs_C = inputs_A.squeeze(1), inputs_B.squeeze(1), inputs_C.squeeze(1)\n",
    "        \n",
    "        return self.p_B(inputs_B) + self.p_C_B(inputs_B, inputs_C) + self.p_A_C(inputs_C, inputs_A) \n",
    "\n",
    "    def set_analytical_maximum_likelihood(self, pi_A, pi_B_A, pi_C_B):\n",
    "        pi_A_th = torch.from_numpy(pi_A)\n",
    "        pi_B_A_th = torch.from_numpy(pi_B_A)\n",
    "        pi_C_B_th = torch.from_numpy(pi_C_B)\n",
    "        \n",
    "        log_joint1 = torch.log(pi_A_th.unsqueeze(1)) + torch.log(pi_B_A_th)\n",
    "        log_p_B = torch.logsumexp(log_joint1, dim=0)\n",
    "        \n",
    "        log_joint2 = torch.log(log_p_B.unsqueeze(1)) + torch.log(pi_C_B_th) \n",
    "        log_p_C = torch.logsumexp(log_joint2, dim=0)\n",
    "        \n",
    "        log_p_C_A = (log_p_C + torch.log(pi_C_B_th) + torch.log(pi_B_A_th)).t - torch.log(pi_A_th.unsqueeze(1))\n",
    "        log_joint3 = torch.log(pi_A_th.unsqueeze(1)) + log_p_C_A\n",
    "        \n",
    "        self.p_B.w.data = log_p_B\n",
    "        self.p_C_B.w.data = torch.log(pi_C_B_th)\n",
    "        self.p_A_C.w.data = log_joint3.t() - log_p_C.unsqueeze(1)\n",
    "\n",
    "    def init_parameters(self):\n",
    "        self.p_B.init_parameters()\n",
    "        self.p_C_B.init_parameters()\n",
    "        self.p_A_C.init_parameters()\n",
    "                \n",
    "class Model7(Model_new):\n",
    "    def __init__(self, N):\n",
    "        super(Model7, self).__init__(N=N)\n",
    "        self.p_B = Marginal(N)\n",
    "        self.p_A_B = Conditional(N)\n",
    "        self.p_C_B = Conditional(N)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Compute the (negative) log-likelihood with the\n",
    "        # decomposition p(x_A, x_B ,x_C) = p(x_B) p(x_A | x_B) p(x_C | x_B)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = torch.split(inputs, 1, dim=1)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = inputs_A.squeeze(1), inputs_B.squeeze(1), inputs_C.squeeze(1)\n",
    "\n",
    "        return self.p_B(inputs_B) + self.p_A_B(inputs_B, inputs_A) + self.p_C_B(inputs_B, inputs_C)\n",
    "\n",
    "    def set_analytical_maximum_likelihood(self, pi_A, pi_B_A,pi_C_B):\n",
    "        pi_A_th = torch.from_numpy(pi_A)\n",
    "        pi_B_A_th = torch.from_numpy(pi_B_A)\n",
    "        pi_C_B_th = torch.from_numpy(pi_B_C)\n",
    "        \n",
    "        log_joint1 = torch.log(pi_A_th.unsqueeze(1)) + torch.log(pi_B_A_th)\n",
    "        log_p_B = torch.logsumexp(log_joint1, dim=0)\n",
    "        \n",
    "        log_joint2 = torch.log(log_p_B.unsqueeze(1)) + torch.log(pi_C_B_th) \n",
    "        log_p_C = torch.logsumexp(log_joint2, dim=0)\n",
    "        \n",
    "        self.p_B.w.data = log_p_B\n",
    "        self.p_A_B.w.data = log_joint1.t() - log_p_B.unsqueeze(1)\n",
    "        self.p_C_B.w.data = torch.log(pi_C_B_th)\n",
    "\n",
    "    def init_parameters(self):\n",
    "        self.p_B.init_parameters()\n",
    "        self.p_A_B.init_parameters()\n",
    "        self.p_C_B.init_parameters()\n",
    "        \n",
    "class Model8(Model_new):\n",
    "    def __init__(self, N):\n",
    "        super(Model4, self).__init__(N=N)\n",
    "        self.p_A = Marginal(N)\n",
    "        self.p_B_A = Conditional(N)\n",
    "        self.p_B_C = Conditional(N)\n",
    "        self.p_C = Marginal(N)\n",
    "        self.p_B = Marginal(N)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Compute the (negative) log-likelihood with the\n",
    "        # decomposition p(x_A, x_B, x_C) = p(x_C)p(x_B | x_A, x_C)p(x_A)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = torch.split(inputs, 1, dim=1)\n",
    "        inputs_A, inputs_B, inputs_C = inputs_A.squeeze(1), inputs_B.squeeze(1), inputs_C.squeeze(1)\n",
    "        \n",
    "        return self.p_A(inputs_A) + (self.p_B_A(inputs_A, inputs_B) * self.p_B_C(inputs_C, inputs_B) * self.p_B(inputs_B))/ (self.p_A(inputs_A) * self.p_C(inputs_C)) + self.p_C(inputs_C) \n",
    "\n",
    "    def set_analytical_maximum_likelihood(self, pi_A, pi_B_A, pi_C_B):\n",
    "        pi_A_th = torch.from_numpy(pi_A)\n",
    "        pi_B_A_th = torch.from_numpy(pi_B_A)\n",
    "        pi_C_B_th = torch.from_numpy(pi_B_C)\n",
    "        \n",
    "        log_joint1 = torch.log(pi_A_th.unsqueeze(1)) + torch.log(pi_B_A_th)\n",
    "        log_p_A = torch.logsumexp(log_joint1, dim=0)\n",
    "        \n",
    "        log_joint2 = torch.log(log_p_B.unsqueeze(1)) + torch.log(pi_C_B_th) \n",
    "        log_p_C = torch.logsumexp(log_joint2, dim=0)\n",
    "        \n",
    "        self.p_A.w.data = log_p_A\n",
    "        self.p_B_A.w.data = torch.log(pi_B_A_th)\n",
    "        self.p_B_C.w.data = log_joint2.t() - log_p_C.unsqueeze(1)\n",
    "        self.p_C.w.data = log_p_C\n",
    "\n",
    "    def init_parameters(self):\n",
    "        self.p_B.init_parameters()\n",
    "        self.p_B_A.init_parameters()\n",
    "        self.p_B_C.init_parameters()\n",
    "        self.p_C.init_parameters()\n",
    "        self.p_A.init_parameters()\n",
    "        \n",
    "class Model9(Model_new):\n",
    "    def __init__(self, N):\n",
    "        super(Model7, self).__init__(N=N)\n",
    "        self.p_A = Marginal(N)\n",
    "        self.p_B_A = Conditional(N)\n",
    "        self.p_C_A = Conditional(N)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Compute the (negative) log-likelihood with the\n",
    "        # decomposition p(x_A, x_B ,x_C) = p(x_A) p(x_B | x_A) p(x_C | x_A)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = torch.split(inputs, 1, dim=1)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = inputs_A.squeeze(1), inputs_B.squeeze(1), inputs_C.squeeze(1)\n",
    "\n",
    "        return self.p_A(inputs_A) + self.p_B_A(inputs_A, inputs_B) + self.p_C_A(inputs_A, inputs_C)\n",
    "\n",
    "    def set_analytical_maximum_likelihood(self, pi_A, pi_B_A, pi_C_B):\n",
    "        pi_A_th = torch.from_numpy(pi_A)\n",
    "        pi_B_A_th = torch.from_numpy(pi_B_A)\n",
    "        pi_C_B_th = torch.from_numpy(pi_B_C)\n",
    "        \n",
    "        log_joint1 = torch.log(pi_A_th.unsqueeze(1)) + torch.log(pi_B_A_th)\n",
    "        log_p_B = torch.logsumexp(log_joint1, dim=0)\n",
    "        \n",
    "        log_joint2 = torch.log(log_p_B.unsqueeze(1)) + torch.log(pi_C_B_th) \n",
    "        log_p_C = torch.logsumexp(log_joint2, dim=0)\n",
    "        \n",
    "        log_joint3 = log_p_C + torch.log(pi_C_B_th) + torch.log(pi_B_A_th) \n",
    "        \n",
    "        self.p_A.w.data = torch.log(pi_A_th)\n",
    "        self.p_B_A.w.data = torch.log(pi_B_A_th)\n",
    "        self.p_C_A.w.data = log_joint3.t() - torch.log(pi_A_th.unsqueeze(1))\n",
    "\n",
    "    def init_parameters(self):\n",
    "        self.p_B.init_parameters()\n",
    "        self.p_B_A.init_parameters()\n",
    "        self.p_C_A.init_parameters()\n",
    "        \n",
    "class Model10(Model_new):\n",
    "    def __init__(self, N):\n",
    "        super(Model4, self).__init__(N=N)\n",
    "        self.p_A = Marginal(N)\n",
    "        self.p_A_B = Conditional(N)\n",
    "        self.p_A_C = Conditional(N)\n",
    "        self.p_C = Marginal(N)\n",
    "        self.p_B = Marginal(N)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Compute the (negative) log-likelihood with the\n",
    "        # decomposition p(x_A, x_B, x_C) = p(x_C)p(x_B | x_A, x_C)p(x_A)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = torch.split(inputs, 1, dim=1)\n",
    "        inputs_A, inputs_B, inputs_C = inputs_A.squeeze(1), inputs_B.squeeze(1), inputs_C.squeeze(1)\n",
    "        \n",
    "        return self.p_A(inputs_A) + (self.p_A_B(inputs_B, inputs_A) * self.p_A_C(inputs_C, inputs_A) * self.p_A(inputs_A))/ (self.p_B(inputs_B) * self.p_C(inputs_C)) + self.p_C(inputs_C) \n",
    "\n",
    "    def set_analytical_maximum_likelihood(self, pi_A, pi_B_A, pi_C_B):\n",
    "        pi_B_th = torch.from_numpy(pi_B)\n",
    "        pi_B_A_th = torch.from_numpy(pi_B_A)\n",
    "        pi_C_B_th = torch.from_numpy(pi_B_C)\n",
    "        \n",
    "        log_joint1 = torch.log(pi_A_th.unsqueeze(1)) + torch.log(pi_B_A_th)\n",
    "        log_p_A = torch.logsumexp(log_joint1, dim=0)\n",
    "        \n",
    "        log_joint2 = torch.log(log_p_B.unsqueeze(1)) + torch.log(pi_C_B_th) \n",
    "        log_p_C = torch.logsumexp(log_joint2, dim=0)\n",
    "        \n",
    "        log_p_C_A = (log_p_C + torch.log(pi_C_B_th) + torch.log(pi_B_A_th)).t - torch.log(pi_A_th.unsqueeze(1))\n",
    "        log_joint3 = torch.log(pi_A_th.unsqueeze(1)) + log_p_C_A\n",
    "        \n",
    "        self.p_A.w.data = log_p_A\n",
    "        self.p_A_B.w.data = log_joint1.t() - log_p_B.unsqueeze(1)\n",
    "        self.p_A_C.w.data = log_joint3.t() - log_p_C.unsqueeze(1)\n",
    "        self.p_C.w.data = log_p_C\n",
    "\n",
    "    def init_parameters(self):\n",
    "        self.p_B.init_parameters()\n",
    "        self.p_A_B.init_parameters()\n",
    "        self.p_A_C.init_parameters()\n",
    "        self.p_C.init_parameters()\n",
    "        self.p_A.init_parameters()\n",
    "        \n",
    "class Model11(Model_new):\n",
    "    def __init__(self, N):\n",
    "        super(Model7, self).__init__(N=N)\n",
    "        self.p_C = Marginal(N)\n",
    "        self.p_A_C = Conditional(N)\n",
    "        self.p_B_C = Conditional(N)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Compute the (negative) log-likelihood with the\n",
    "        # decomposition p(x_A, x_B ,x_C) = p(x_A) p(x_B | x_A) p(x_C | x_A)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = torch.split(inputs, 1, dim=1)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = inputs_A.squeeze(1), inputs_B.squeeze(1), inputs_C.squeeze(1)\n",
    "\n",
    "        return self.p_C(inputs_C) + self.p_A_C(inputs_C, inputs_A) + self.p_B_C(inputs_C, inputs_B)\n",
    "\n",
    "    def set_analytical_maximum_likelihood(self, pi_A, pi_B_A, pi_C_B):\n",
    "        pi_A_th = torch.from_numpy(pi_A)\n",
    "        pi_B_A_th = torch.from_numpy(pi_B_A)\n",
    "        pi_C_B_th = torch.from_numpy(pi_B_C)\n",
    "        \n",
    "        log_joint1 = torch.log(pi_A_th.unsqueeze(1)) + torch.log(pi_B_A_th)\n",
    "        log_p_B = torch.logsumexp(log_joint1, dim=0)\n",
    "        \n",
    "        log_joint2 = torch.log(log_p_B.unsqueeze(1)) + torch.log(pi_C_B_th) \n",
    "        log_p_C = torch.logsumexp(log_joint2, dim=0)\n",
    "         \n",
    "        log_p_C_A = (log_p_C + torch.log(pi_C_B_th) + torch.log(pi_B_A_th)).t - torch.log(pi_A_th.unsqueeze(1))\n",
    "        log_joint3 = torch.log(pi_A_th.unsqueeze(1)) + log_p_C_A\n",
    "        \n",
    "        self.p_C.w.data = torch.log(pi_A_th)\n",
    "        self.p_A_C.w.data =  log_joint3.t() - log_p_C.unsqueeze(1)\n",
    "        self.p_B_C.w.data = log_joint2.t() - log_p_C.unsqueeze(1)\n",
    "\n",
    "    def init_parameters(self):\n",
    "        self.p_C.init_parameters()\n",
    "        self.p_A_C.init_parameters()\n",
    "        self.p_B_C.init_parameters()\n",
    "        \n",
    "class Model12(Model_new):\n",
    "    def __init__(self, N):\n",
    "        super(Model4, self).__init__(N=N)\n",
    "        self.p_A = Marginal(N)\n",
    "        self.p_C_A = Conditional(N)\n",
    "        self.p_C_B = Conditional(N)\n",
    "        self.p_C = Marginal(N)\n",
    "        self.p_B = Marginal(N)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Compute the (negative) log-likelihood with the\n",
    "        # decomposition p(x_A, x_B, x_C) = p(x_C)p(x_B | x_A, x_C)p(x_A)\n",
    "        \n",
    "        inputs_A, inputs_B, inputs_C = torch.split(inputs, 1, dim=1)\n",
    "        inputs_A, inputs_B, inputs_C = inputs_A.squeeze(1), inputs_B.squeeze(1), inputs_C.squeeze(1)\n",
    "        \n",
    "        return self.p_A(inputs_A) + (self.p_C_A(inputs_A, inputs_C) * self.p_C_B(inputs_B, inputs_C) * self.p_C(inputs_C))/ (self.p_B(inputs_B) * self.p_A(inputs_A)) + self.p_B(inputs_B) \n",
    "\n",
    "    def set_analytical_maximum_likelihood(self, pi_A, pi_B_A, pi_C_B):\n",
    "        pi_B_th = torch.from_numpy(pi_B)\n",
    "        pi_B_A_th = torch.from_numpy(pi_B_A)\n",
    "        pi_C_B_th = torch.from_numpy(pi_B_C)\n",
    "        \n",
    "        log_joint1 = torch.log(pi_A_th.unsqueeze(1)) + torch.log(pi_B_A_th)\n",
    "        log_p_A = torch.logsumexp(log_joint1, dim=0)\n",
    "        \n",
    "        log_joint2 = torch.log(log_p_B.unsqueeze(1)) + torch.log(pi_C_B_th) \n",
    "        log_p_C = torch.logsumexp(log_joint2, dim=0)\n",
    "        \n",
    "        log_joint3 = log_p_C + torch.log(pi_C_B_th) + torch.log(pi_B_A_th) \n",
    "        \n",
    "        self.p_A.w.data = log_p_A\n",
    "        self.p_C_A.w.data = log_joint3.t() - torch.log(pi_A_th.unsqueeze(1))\n",
    "        self.p_C_B.w.data = torch.log(pi_C_B_th)\n",
    "        self.p_C.w.data = log_p_C\n",
    "\n",
    "    def init_parameters(self):\n",
    "        self.p_B.init_parameters()\n",
    "        self.p_C_A.init_parameters()\n",
    "        self.p_C_B.init_parameters()\n",
    "        self.p_C.init_parameters()\n",
    "        self.p_A.init_parameters()\n",
    "        \n",
    "class StructuralModel(BivariateStructuralModel):\n",
    "    def __init__(self, num_categories):\n",
    "        \n",
    "        model_A_B_C = Model1(num_categories)\n",
    "        model_C_B_A = Model2(num_categories)\n",
    "        \n",
    "        model_B_A_C = Model3(num_categories)\n",
    "        model_C_A_B = Model4(num_categories)\n",
    "        \n",
    "        model_A_C_B = Model5(num_categories)\n",
    "        model_B_C_A = Model6(num_categories)\n",
    "\n",
    "        super(StructuralModel, self).__init__(model_A_B_C, model_C_B_A, model_B_A_C, model_C_A_B, model_A_C_B, model_B_C_A)\n",
    "        self.w = nn.Parameter(torch.tensor(0., dtype=torch.float64))\n",
    "    \n",
    "    def set_analytical_maximum_likelihood(self, pi_A, pi_B_A, pi_C_B ):\n",
    "        self.model_A_B_C.set_analytical_maximum_likelihood(pi_A, pi_B_A, pi_C_B)\n",
    "        self.model_C_B_A.set_analytical_maximum_likelihood(pi_A, pi_B_A, pi_C_B)\n",
    "        self.model_B_A_C.set_analytical_maximum_likelihood(pi_A, pi_B_A, pi_C_B)\n",
    "        self.model_C_A_B.set_analytical_maximum_likelihood(pi_A, pi_B_A, pi_C_B)\n",
    "        self.model_A_C_B.set_analytical_maximum_likelihood(pi_A, pi_B_A, pi_C_B)\n",
    "        self.model_B_C_A.set_analytical_maximum_likelihood(pi_A, pi_B_A, pi_C_B)\n",
    "\n",
    "    def set_maximum_likelihood(self, inputs):\n",
    "        self.model_A_B_C.set_maximum_likelihood(inputs)\n",
    "        self.model_C_B_A.set_maximum_likelihood(inputs)\n",
    "        self.model_B_A_C.set_maximum_likelihood(inputs)\n",
    "        self.model_C_A_B.set_maximum_likelihood(inputs)\n",
    "        self.model_A_C_B.set_maximum_likelihood(inputs)\n",
    "        self.model_B_C_A.set_maximum_likelihood(inputs)\n",
    "\n",
    "    def reset_modules_parameters(self):\n",
    "        self.model_A_B_C.init_parameters()\n",
    "        self.model_C_B_A.init_parameters()\n",
    "        self.model_B_A_C.init_parameters()\n",
    "        self.model_C_A_B.init_parameters()\n",
    "        self.model_A_C_B.init_parameters()\n",
    "        self.model_B_C_A.init_parameters()\n",
    "        \n",
    "class StructuralModel_1(BivariateStructuralModel):\n",
    "    def __init__(self, num_categories):\n",
    "        \n",
    "        model_A_B_C = Model7(num_categories)\n",
    "        model_C_B_A = Model8(num_categories)\n",
    "        \n",
    "        model_B_A_C = Model9(num_categories)\n",
    "        model_C_A_B = Model10(num_categories)\n",
    "        \n",
    "        model_A_C_B = Model11(num_categories)\n",
    "        model_B_C_A = Model12(num_categories)\n",
    "\n",
    "        super(StructuralModel_1, self).__init__(model_A_B_C, model_C_B_A, model_B_A_C, model_C_A_B, model_A_C_B, model_B_C_A)\n",
    "        self.w = nn.Parameter(torch.tensor(0., dtype=torch.float64))\n",
    "    \n",
    "    def set_analytical_maximum_likelihood(self, pi_B, pi_B_A, pi_B_C):\n",
    "        self.model_A_B_C.set_analytical_maximum_likelihood(pi_B, pi_B_A, pi_B_C)\n",
    "        self.model_C_B_A.set_analytical_maximum_likelihood(pi_B, pi_B_A, pi_B_C)\n",
    "        self.model_A_B_C.set_analytical_maximum_likelihood(pi_A, pi_B_A, pi_C_B)\n",
    "        self.model_C_B_A.set_analytical_maximum_likelihood(pi_A, pi_B_A, pi_C_B)\n",
    "        self.model_B_A_C.set_analytical_maximum_likelihood(pi_A, pi_B_A, pi_C_B)\n",
    "        self.model_C_A_B.set_analytical_maximum_likelihood(pi_A, pi_B_A, pi_C_B)\n",
    "        self.model_A_C_B.set_analytical_maximum_likelihood(pi_A, pi_B_A, pi_C_B)\n",
    "        self.model_B_C_A.set_analytical_maximum_likelihood(pi_A, pi_B_A, pi_C_B)\n",
    "\n",
    "    def set_maximum_likelihood(self, inputs):\n",
    "        self.model_A_B_C.set_maximum_likelihood(inputs)\n",
    "        self.model_C_B_A.set_maximum_likelihood(inputs)\n",
    "        self.model_B_A_C.set_maximum_likelihood(inputs)\n",
    "        self.model_C_A_B.set_maximum_likelihood(inputs)\n",
    "        self.model_A_C_B.set_maximum_likelihood(inputs)\n",
    "        self.model_B_C_A.set_maximum_likelihood(inputs)\n",
    "\n",
    "\n",
    "    def reset_modules_parameters(self):\n",
    "        self.model_A_B_C.init_parameters()\n",
    "        self.model_C_B_A.init_parameters()\n",
    "        self.model_B_A_C.init_parameters()\n",
    "        self.model_C_A_B.init_parameters()\n",
    "        self.model_A_C_B.init_parameters()\n",
    "        self.model_B_C_A.init_parameters()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
